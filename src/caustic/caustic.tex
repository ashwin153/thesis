\documentclass[../main.tex]{subfiles}

\begin{document}
In this chapter, we will discuss Caustic. Caustic is a transactional programming language that
allows programs to be written as if they were single-threaded applications, but permits them to be
distributed arbitrarily without error. We first motivate transactional programming by
discussing race conditions and the various techniques that are typically used to deal with them. We
then discuss the various components of Caustic: a \textbf{runtime} that executes programs, a
\textbf{standard library} that simplifies program construction, and a \textbf{compiler} that
simplifies program expression. We conclude with an evaluation of the programmability and
performance of the language.

% Race Conditions.
\section{Race Conditions}
Race conditions may occur whenever the order of execution of concurrent programs affects their
outcome. For example, suppose there exist two programs $A$ and $B$ that each increment a shared
counter $x$. Each program must first read the current value of $x$ in order to write $x + 1$. If
$B$ reads \emph{after} $A$ writes, then $B$ reads $x + 1$ and writes $x + 2$. However, if $B$ reads
\emph{before} $A$ writes but after $A$ reads, then both $A$ and $B$ will read $x$ and write $x + 1$.
This is an example of a race condition, because the value of the counter $x$ after both $A$ and $B$
are executed depends on the order in which $A$ and $B$ are executed. This race condition may seem
relatively benign, but it can have catastrophic consequences in practical systems. Suppose the value
of $x$ corresponded to your bank balance. What if your bank determined your balance differently
depending on the order in which deposits are made? Race conditions manifest themselves in subtle
ways in concurrent systems, and they can often be difficult to detect and challenging to remove.

Before introducing mechanisms to deal with race conditions, we must first define the necessary and
sufficient criteria that any such mechanism must satisfy to correctly mitigate race conditions.
Race conditions are a relatively well-studied problem in database literature, and we may draw upon
known results from the field to define four properties of race-free programs.~\cite{transactions}
We will hereafter refer to anything that satisfies these properties as \textbf{transactional}.

\begin{itemize}
  \item \textbf{Atomic}: Programs are all-or-nothing; they are never partially applied.
  \item \textbf{Consistent}: Programs see the effect of all completed programs.
  \item \textbf{Isolated}: Programs cannot see the effect of in-progress programs.
  \item \textbf{Durable}: The effects of completed programs are permanently visible.
\end{itemize}

  % Locks and Leases.
  \subsection{Locks and Leases}
  A common approach to dealing with race conditions is locking. Before a program accesses or
  modifies shared data, it first declares its intentions to other programs by acquiring a
  lock that it subsequently releases when it is finished with the data. Locks are trivially
  transactional because they require programs to have exclusive ownership before performing any
  operations on shared data. However, locking introduce new problems.

  First, concurrent acquisition of multiple locks can cause a deadlock that prevents the system from
  making progress. For example, if program $A$ acquires lock $x$ and then attempts to acquire lock
  $y$ and program $B$ acquires $y$ and then attempts to acquire $x$, then neither $A$ nor $B$ can
  make progress because each is waiting for the other to release their lock. This problem is
  typically mitigated by imposing a total order on lock acquisition; for any two locks $x$ and $y$,
  $x$ will always be acquired before $y$ or $y$ will always be acquired before $x$.

  Second, faulty programs may never release their locks. For example, if program $A$ acquires lock
  $x$ and subsequently fails, then no other program can ever acquire $x$. This problem is typically
  mitigated by using leases.~\cite{leases} A lease is a lock that is automatically released after a
  certain amount of time. Programs must be carefully constructed so that they complete their
  operations on shared data within the lease duration or refresh the lease before it expires.

  Third, locking is expensive. Locks must be acquired regardless of whether or not there actually
  are concurrent operations on shared data, because programs cannot know if there are or will be
  other programs that want or will want to simultaneously use the data. This significantly degrades
  performance in situations where contention between programs is low.

  Fourth, locking cannot protect against programmer error. Programmers may omit or incorrectly use a
  lock and thereby introduce race conditions into their program. Locks cannot guarantee they will be
  used correctly, and, therefore, cannot guarantee that race conditions will be exhaustively
  eliminated from a program.

  % Database Transactions.
  \subsection{Database Transactions}
  An alternative approach is to use a transactional database to protect shared data from concurrent
  modification. There exist a number of transactional storage systems. However, each of these
  storage systems has their own bespoke interface for specifying transactions that are often lacking
  in functionality and performance. Recent years have marked a proliferation in NoSQL databases that
  scale well by shedding functionality. These databases were not popularized because of their query
  languages, they were \emph{in spite} of them. Some, like Cassandra and Aerospike, attempt to mimic
  the relational semantics of SQL, but they fall short of implementing the entire SQL specification.
  Others, like MongoDB and DynamoDB, implement entirely new query languages. Even SQL is not beyond
  reproach. SQL lacks a canonical implementation and has ambiguous and unintuitive syntax.
  ~\cite{sql} Relational databases like MySQL and PostgreSQL that each claim to implement the same
  SQL specification actually support incompatible subsets of its functionality. Stark differences
  between query languages tightly couples storage systems and the programs that are run on them, and
  makes the choice of database in an application effectively permanent. While transactional storage
  systems provide the necessary guarantees on which correct distributed systems can be built, their
  collective lack of a robust and uniform interface makes it all but impossible to design
  non-trivial applications.

  % Optimistic Concurrency.
  \subsection{Optimistic Concurrency}
  Optimistic concurrency allows multiple programs to simultaneously access, but not modify, shared
  data without acquiring locks. Each program locally buffers any modifications that it makes and
  attempts to atomically apply them when it completes conditioned on the data that it accessed
  remaining unchanged. If any data was modified, the program retries. This conditional update, known
  as a multi-word compare-and-swap, is known to be transactional and is widely used in a number of
  software transactional memory systems~\cite{stm} including Sinfonia~\cite{sinfonia} and Caustic.
  We will hereafter refer to the operation as \textbf{cas} and its arguments as a
  \textbf{transaction}. Optimistic concurrency assumes that contention between programs will be low,
  because frequent retries can significantly degrade performance.

  Optimistic concurrency requires a mechanism to detect that data has changed. The approach taken in
  Caustic and in similar systems is to uniquely identify data with a \textbf{key} and to associate
  each key with \textbf{revision}, or versioned value, whose version is incremented each time that
  its value is changed. We say that revisions $A$ and $B$ for a key \textbf{conflict} if the version
  of $A$ is less than $B$. Note that conflict is an asymmetric relation; if $A$ conflicts with $B$,
  then $B$ does not conflict with $A$.

% Runtime.
\section{Runtime}
The runtime is a virtual machine that dynamically translates a \textbf{program} into a transaction.
A program is an abstract-syntax tree that is composed of \textbf{literals} and \textbf{expressions}.
A literal is a scalar value of type flag, real, text, and null which correspond to bool, double,
string, and null respectively in most C-style languages. An expression is a function that transforms
literal arguments into a literal result. Expressions may be chained together arbitrarily to form
complex programs. Table~\ref{table:expressions} enumerates the various expressions natively
supported by the runtime.

We will assume the existence of an underlying key-value store, called a \textbf{volume}, that
supports \textbf{get} and \textbf{cas}. Note that get is non-transactional, so programs may read
stale revisions during execution. However, execution must terminate with a successful cas regardless
of whether or not the program performs any writes. This guarantees that successfully executed
programs will always read a consistent snapshot. We will provide a distributed, fault-tolerant
implementation of a volume in Beaker. For now, we will assume that such an implementation exists.

  % Execution.
  \subsection{Execution}
  The runtime uses iterative partial evaluation to gradually reduce programs into a single literal
  result. Given correct implementations of get and cas, the runtime executes programs according to
  the following procedure.

  \begin{enumerate}
    \item \textbf{Fetch}: Get all keys that are read or written by the program that have not been
          fetched before and add the returned revisions to a local \textbf{snapshot}.
    \item \textbf{Evaluate}: Recursively replace all expressions with literal arguments with their
          corresponding literal result. For example,

          \[
          \begin{gathered}
          add(real(1), sub(real(0), real(2))) \rightarrow real(-1)
          \end{gathered}
          \]

          The result of all writes is saved to a local \textbf{buffer} and the result of all reads
          is the latest value of the key in the local buffer or snapshot. This ensures that reads
          will see the effect of all previous writes within the program.
    \item \textbf{Repeat}: Loop until the program is reduced to a single literal. Because all
          expressions with literal arguments return a literal result, all programs will eventually
          reduce to a single literal.
    \item \textbf{Commit}: Cas all keys in the local buffer conditioned on all revisions in
          the local snapshot. The transactional guarantees of cas imply that program execution is
          \textbf{serializable}. Serializability means that concurrent execution has the
          same effect as some sequential execution, and, therefore, that program execution will be
          robust against race conditions.
  \end{enumerate}

  % Optimizations.
  \subsection{Optimizations}
  First, execution is tail-recursive. Therefore, programs may be composed of arbitrarily many
  nested expressions without overflowing the stack frame. This also allows the Scala compiler to
  aggressively optimize execution into a tight loop. Second, the runtime batches I/O. Reads are
  performed simultaneously whenever possible and writes are buffered and simultaneously committed.
  By batching I/O, the runtime performs a minimal number of operations on the database. This has
  significant performance implications, because I/O overhead is overwhelmingly the bottleneck by
  many orders of magnitude.~\cite{io}

% Standard Library.
\section{Standard Library}
The runtime provides native support for an extremely limited subset of the operations that
programmers typically rely on to write programs. The standard library supplements the
functionality of the runtime by exposing a rich Scala DSL complete with static types, records,
math, collections, and control flow.

  % Typing.
  \subsection{Typing}
  The runtime natively supports just four dynamic types: flag, real, text, and null.
  Dynamic versus static typing is a religious debate among programmers. Advocates of dynamic
  typing often mistakenly believe that type inference and coercive subtyping cannot be provided by
  a static type system. In fact, they can. Because static type systems are able to
  detect type inaccuracies at compile-time, they allow programmers to write more concise and
  correct code.~\cite{typing} The standard library provides rich static types and features
  aggressive type inference and subtype polymorphism.

  The standard library supports four \textbf{primitive} types. In ascending order of precedence,
  they are \textbf{boolean}, \textbf{int}, \textbf{double}, and \textbf{string}. A \texbf{value}
  represents a scalar value. There are two kinds of values. A \textbf{constant} is an immutable
  value, and a \textbf{variable} is a mutable value. Variables may be stored locally in memory or
  remotely in a database. The standard library uses implicit conversions to coerce Scala literals
  into their corresponding Caustic type.

  \begin{lstlisting}[style=Scala]
    // Creates an integer local variable named x.
    val x = Variable.Local[Int]("x")
    // Creates a floating point remote variable named y.
    val y = Variable.Remote[Double]("y")
    // Assigns y to the sum of x and y.
    y := x + y
    // Assigns x to the product of x and y.
    x *= 4
    // Does not compile, because y is not an integer.
    x := y
  \end{lstlisting}

  % Records.
  \subsection{Records}
  In addition to these primitive types, the standard library also supports \textbf{references} to
  user-defined types. References use \href{https://github.com/milessabin/shapeless}{Shapeless} to
  materialize compiler macros that permit the fields of an object to be statically manipulated and
  iterated. A current limitation is that objects cannot be self-referential; an object cannot have a
  field of its own type.

  \begin{lstlisting}[style=Scala]
    // An example type declaration.
    case class Bar(
      a: String,
    )

    case class Foo(
      b: Int,
      c: Reference[Bar],
      d: Bar
    )

    // Constructs a remote reference to a Foo.
    val x = Reference[Foo](Variable.Remote("x"))
    // Returns the value of the field b.
    x.get(@<'b>@)
    // Does not compile, because z is not a field of Foo.
    x.get(@<'z>@)
    // Serializes x to a JSON string.
    x.asJson
    // Deletes all fields of x and all references.
    x.delete(recursive = true)
    // Constructs a local reference to a Foo.
    val y = Reference[Foo](Variable.Local("y"))
    // Copies x to y.
    y := x
  \end{lstlisting}

  % Math.
  \subsection{Math}
  The runtime natively supports just nine mathematical operations: add, sub, mul, div, pow,
  log, floor, sin, and cos. However, these primitive operations are sufficient to derive the
  entire Scala \href{https://www.scala-lang.org/api/2.12.1/scala/math/index.html}{math} library using
  various mathematical identities and Taylor series approximations. The div, log, sin, and
  cos functions can actually be implemented in terms of the other primitive operations; however,
  native support for them was included in the runtime to improve performance. The standard library
  provides implementations for all functions enumerated in Table~\ref{table:math}.

  \begin{lstlisting}[style=Scala]
    // Returns the Taylor approximation of inverse sine.
    asin(Pi / 2)
    // Defines the sigmoid function.
    def sigmoid(x: Value[Double]) = exp(x) / (exp(x) + 1)
  \end{lstlisting}

  % Collections.
  \subsection{Collections}
  The runtime has no native support for collections of key-value pairs. The standard library
  provides implementations of three fundamental data structures: \textbf{list}, \textbf{set},
  and \textbf{map}. These collections are mutable and statically-typed. Collections take care of the
  messy details of mapping structured data onto a flat namespace, and feature prefetched iteration.
  A current limitation is that collections may only contain primitive types.

  \begin{lstlisting}[style=Scala]
    // Constructs a map from string to boolean.
    val x = Map[String, Boolean](Variable.Remote("y"))
    // Puts an entry in the map.
    x += "foo" -> true
    // Serializes x to a JSON string.
    x.asJson
    // Constructs a list of integers.
    val x = List[Int](Variable.Local("x"))
    // Increments each element in the list.
    x.foreach(_ + 1)
  \end{lstlisting}

  % Control Flow.
  \subsection{Control Flow}
  The runtime has native support for control flow operations like branch, cons, and repeat.
  However, it is syntactically challenging to express these contructs. The standard library
  uses structural types to provide support for \textbf{if}, \textbf{while}, \textbf{return},
  \textbf{assert}, and \textbf{rollback}. The standard library uses an implicitly available parsing
  \textbf{context} to track modifications made to variables, references, and collections and to
  detect when any control flow statements are called.

  \begin{lstlisting}[style=Scala]
    // If statements.
    If (x < 3) {
      x += 3
    }

    // If/Else statements
    If (y < x) {
      y += 1
    } Else {
      x += 1
    }

    // Ternary operator.
    val z = If (y === x) { y - 1 } Else { y + 1 }

    // While loops.
    While (x <> y) {
      x *= 2
    }
  \end{lstlisting}

% Compiler.
\section{Compiler}
The standard library provides additional functionality that is absent in the runtime to make it
easier to construct programs. However, the standard library does not address the syntactic
challenges of expressing programs. At times the standard library is forced to use unintuitive
operators like $:=$ and $<>$ and verbose declarations like $Variable.Remote(``x")$, because it is a
language within a language.

The compiler translates programs written in the statically-typed, object-oriented Caustic
programming language into operations on the standard library. For example, consider the following
example of a distributed counter written in Caustic. This program may be run without modification
on any underlying volume and distributed arbitrarily without error. The Akka project also provides
a similar \href{https://git.io/vxS6u}{implementation} of a backend-agnostic distributed counter.
Their implementation is almost seven times longer.

\begin{lstlisting}[style=Caustic]
  module caustic.example

  /**
   * A count.
   *
   * @param value Current value.
   */
  record Total {
    value: Int
  }

  /**
   * A distributed counter.
   */
  service Counter {

    /**
     * Increments the total and returns its current value.
     *
     * @param x Reference to total.
     * @return Current value.
     */
    def increment(x: Total&): Int = {
      if (x.value) x.value += 1 else x.value = 1
      x.value
    }

  }
\end{lstlisting}

  % Implementation.
  \subsection{Implementation}
  The compiler uses ANTLR \cite{antlr} to generate a predicated LL(*) parser from an ANTLR grammar
  file. The compiler parses source files and then walks the resulting parse-tree to generate code.
  Code generation is relatively straightforward. Most statements in Caustic have direct equivalents
  in the standard library. For the most part, the compiler acts as a kind of intelligent
  find-and-replace. However, there are certain aspects of the compiler that are non-trivial.

  First, the compiler performs type-inference. It is able statically verify types and method
  signatures by maintaining a lexically-scope \textbf{universe} of the various variables, records,
  and functions that have been defined. Second, the compiler is directly integrated in the
  \hyperref{https://www.pantsbuild.org/}{Pants} build system. Third, the compiler provides a
  \hyperref{https://macromates.com/}{TextMate} bundle that implements syntax highlighting and code
  completion for most text editors and IDEs.

% Evaluation.
\section{Evaluation}

% Conclusion.
\section{Conclusion}


\end{document}